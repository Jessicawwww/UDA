{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU 95-865 Spring 2022 Quiz 2 K4\n",
    "\n",
    "**Make sure your Zoom video is on and that you can see/hear the course staff.**\n",
    "\n",
    "This is an 80 minute exam. We will only grade what is submitted via Canvas.\n",
    "\n",
    "You must fill in your name and your Andrew ID for this quiz to be graded. Moreover, filling out your name and Andrew ID below will serve as your agreement with us, the course staff, that you did not collaborate with anyone on this exam and that what you submit is truly your own individual work and not that of anyone else. Violations found will result in severe penalties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your name: jingyi Wu\n",
    "\n",
    "Your Andrew ID: jingyiw2\n",
    "\n",
    "**Warning: If you leave the above blank, your quiz will not be graded.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** There are 3 problems that can be done in any order. Problem 1 (32 points) and Problem 2 (16 points) have no coding. Problem 3 is mostly on coding with a few non-coding interpretation parts (52 points total: 42 are for coding, and the other 10 are for non-coding interpretations/explanations).\n",
    "\n",
    "**Throughout the coding problem, do *not* import any additional packages/functions/classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Diagnostic radiology (no coding) [32 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've been hired to work with Dr. Sitoh, a diagnostic radiologist at the National University Hospital of Singapore. He reviews many diagnostic scans every day, specifically of the following 6 types: \n",
    "-  Abdominal CT scans\n",
    "-  Breast MRI scans\n",
    "-  Chest CT scans\n",
    "-  Chest X-rays\n",
    "-  Hand X-rays\n",
    "-  Head CT scans\n",
    "<br>\n",
    "\n",
    "He would like to classify the scans he reviews for his archive, but finds the manual labeling process time consuming. As a student at Heinz College, you tell him that he can use a convolutional neural network (CNN) to automatically classify images of diagnostic scans into the categories above.\n",
    "\n",
    "As a preprocessing step, he has resized every image so that it has the shape (1, 64, 64). Note that some of the medical images are originally 3D, and what he has done is just taken a 2D slice from the 3D image so that we're only working with 2D grayscale images.\n",
    "\n",
    "Dr. Sitoh is wondering if he could use the following CNN to classify each image into the 6 classes; the CNN consists of the following sequence of layers:\n",
    "\n",
    "1. Conv2d layer with $k$ filters, each 3-by-3\n",
    "2. An $m$-by-$m$ MaxPool2d layer\n",
    "3. Conv2d layer with $k$ filters, each 3-by-3\n",
    "4. Flatten\n",
    "5. ReLU\n",
    "6. A linear layer with 1 output node\n",
    "7. ReLU\n",
    "8. A linear layer with 100 output nodes\n",
    "9. Softmax\n",
    "\n",
    "Note that $k$ and $m$ are positive integer constants.\n",
    "\n",
    "**For this problem, do not write code. In particular, if your answer to any part of this problem has code, then that part will not receive any credit.**\n",
    "\n",
    "**Parts (a), (b), (c), (d), and (e) can be done in any order. The three subparts within part (e) can be done in any order.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) [4 points]** Can the above CNN be used to classify each of the resized 2D grayscale medical images into the 6 classes? Please state yes or no, and be sure to justify your answer. In particular, if you say \"yes\", please briefly explain why the answer is yes. If you say \"no\", please clearly state what would need to be changed with the architecture so that it can be used for classification with 6 classes (please provide as few changes as possible rather than just stating a completely different neural net architecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:**\n",
    "\n",
    "No, the linear layer has output of 100 nodes. If it needs 6 classes, another layer should be added to inpu 100 nodes and output 6 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) [4 points]** How many parameters does the second Conv2d layer have (i.e., the 3rd layer in the sequence of layers above)? Please be sure to provide an explanation of your answer.\n",
    "\n",
    "*Note:* If your answer involves either $k$ or $m$ (it is possible that the answer does not depend on these), please leave $k$ and $m$ unspecified (i.e., do not plug in specific values for them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "\n",
    "k* k* 3 * 3 + k, since the input from previous layer has k channels, and in this layer also has k filters, and 3* 3, so k * k * 3 * 3, and there is k activation parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) [8 points]** For just this part **and not the other parts**, suppose that $m=4$ but $k$ is still left unspecified. For a single data point (of shape (1, 64, 64)) provided to the CNN, what is the shape of the output after the 5th layer (the first ReLU)? Please be sure to provide an explanation of your answer.\n",
    "\n",
    "Note: If your answer involves $k$, please leave $k$ unspecified (i.e., do not plug in a specific value for $k$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "\n",
    "(1, 169). the outputs are (k,62,62), (k,15,15), (k, 13, 13), and flatten, so 1,169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) [4 points]** For a single data point (of shape (1, 64, 64)) provided to the CNN, what is the shape of the output of the 7th layer (the second ReLU)? Please be sure to provide an explanation of your answer.\n",
    "\n",
    "*Note:* If your answer involves either $k$ or $m$ (it is possible that the answer does not depend on these), please leave $k$ and $m$ unspecified (i.e., do not plug in specific values for them).\n",
    "\n",
    "*Hint:* It is possible to answer this part without knowing the answer to part (c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "(1,1), since all 169 are transformed into one node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) [12 points across subparts]** After you and Dr. Sitoh manage to get the CNN trained on his data (and making appropriate changes to the neural net if your answer to part **(a)** was \"no\"), you want to check if the neural net is learning anything interesting. You try the following: you input 3600 medical images into the convnet, and you extract the representation of these images after the 6th layer (i.e., after the first linear layer and before the second ReLU). You plot these 3600 feature vectors using t-SNE and get the following 2D t-SNE plot (where you have colored the different classes using different colors):\n",
    "\n",
    "![t-SNE plot](mystery_pancakes.png)\n",
    "\n",
    "**Important:** The subparts below can be answered in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart i. [4 points]** Given this plot, do you think the CNN has learned what the different classes of medical images are? Please indicate \"yes\" or \"no\" and briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "yes, since in the plot, we can clearly see there are 6 clusters separated large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart ii. [4 points]** Do you think that the 2D t-SNE representation of the feature vectors is well-approximated by a Gaussian mixture model? Briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "\n",
    "Yes, since the points within the cluster are similar enough and clusters are separated enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iii. [4 points]** In training this neural net, the training data were split into a proper training set and a validation set. Per epoch of training, we update neural net parameters only using the proper training set, and then compute the accuracy on the validation set. We try some maximum number of epochs, and decide on the number of epochs to use based on whichever epoch achieved the highest validation set accuracy.\n",
    "\n",
    "Dr. Sitoh's research assistant tells him that he might want to use a test dataset separate from the proper training and validation sets to evaluate the performance of the model, but Dr. Sitoh declines, saying that the validation accuracy is good enough for him.\n",
    "\n",
    "Do you think there is a need for a test dataset separate from the validation dataset used during training? Explain your answer briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:**\n",
    "\n",
    "Yes, since we can use validation sets to help select proper models, and apply on different test sets to see generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Summarizing patents (no coding) [16 points]\n",
    "\n",
    "After fitting LDA to a text dataset of patents, one topic appears to be about AI (so throughout this problem, we will call this topic the \"AI topic\"), with the top 6 most probable words shown below:\n",
    "\n",
    "| Top word       | Probability of word for topic |\n",
    "| -------------- |:--------:|\n",
    "| machine        | 0.20     |\n",
    "| learning       | 0.18     |\n",
    "| robot          | 0.16     |\n",
    "| artificial     | 0.14     |\n",
    "| neural         | 0.13     |\n",
    "| training       | 0.11     |\n",
    "\n",
    "Note that since the LDA model has already been fitted, we can generate words from the model for a particular text document. The parts below are all about this already-fitted generative model and the documents that are generated from it. *Put another way, the questions below assume that the LDA model is actually the \"true\"/correct model and we want to reason about its behavior.*\n",
    "\n",
    "**For this problem, do not write code. In particular, if your answer to any part of this problem has code, then that part will not receive any credit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) [4 points]** When we generate text from the fitted LDA model, should we expect the words \"machine\" and \"learning\" to often appear next to each other? Please clearly state \"yes\" or \"no\", and be sure to explain your answer. Correctly specifying \"yes\" or \"no\" without a correct explanation will not receive full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "\n",
    "Yes, since they are in the same topic cluster and they rank top2 in probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) [4 points]** While we have not provided for you what the 7th most probable word is for the AI topic, could it occur with probability 0.1 for the AI topic? Please clearly state \"yes\" or \"no\", and be sure to explain your answer. Correctly specifying \"yes\" or \"no\" without a correct explanation will not receive full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "\n",
    "Yes, since the previous has prob of 0.11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) [4 points]** If the word \"machine\" turns out to have probability 0 for all other topics learned, does it mean that if we see the word \"machine\" in a text document (generated from the learned LDA model), then we know that this document is definitely partially about the AI topic (so that when we look at the document's membership in the different topics, the fraction of membership in the AI topic is strictly greater than 0)? Please clearly state \"yes\" or \"no\", and be sure to explain your answer. Correctly specifying \"yes\" or \"no\" without a correct explanation will not receive full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "\n",
    "No, since in LDA we tend to filter and keep only high frequency words as the features, maybe machine just appear not enough times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) [4 points]** Suppose that we are given more information: every single text document generated from this LDA model has (strangely) exactly 1 one word. In this case, does the model still allow for \"mixed membership\" (where a text document's underlying truth is that it is part of multiple topics)? Please clearly state \"yes\" or \"no\", and be sure to explain your answer. Correctly specifying \"yes\" or \"no\" without a correct explanation will not receive full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation:** \n",
    "\n",
    "Yes, since one word can appear in several topics and document can still be mixture of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Predicting disasters with Twitter data (mostly coding) [52 points]\n",
    "\n",
    "Note: 42 points in this problem are for coding, and 10 are for non-coding interpretations/explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we analyze text data collected from Twitter about various disasters.\n",
    "\n",
    "Let's first collect some imports. **In this problem, do *not* import any additional packages/functions/classes. Your code should only be using what we have already imported for you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL -- BUT BE SURE TO RUN IT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the text data we will analyze. As a bit of terminology: on the social network Twitter, a post is called a \"tweet\". For this reason, we refer to the different text documents as tweets. Note that all the tweets here have actually already gone through some preprocessing (to remove urls, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 6000\n",
      "\n",
      "Example tweet: 1 of those days when ya dont realize till already in transit that a train derailed at the metro st closest to work\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL -- BUT BE SURE TO RUN IT\n",
    "tweets = np.load('mystery_balloons.npy')\n",
    "print('Number of tweets:', len(tweets))\n",
    "print()\n",
    "print('Example tweet:', tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parts (a), (b), and (c) can be done in any order.**\n",
    "\n",
    "**As a reminder, do not import additional packages/functions/classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) [6 points across subparts]** Let's convert the text data into a representation that we can then do downstream analyses with.\n",
    "\n",
    "**Subpart i. [2 points]** Construct a `TfidfVectorizer` object with the Python variable name `vectorizer`. When you initialize `TfidfVectorizer`, please use the arguments `stop_words='english', min_df=10, max_df=0.8` (do not set any other arguments). Using this vectorizer object, use `fit_transform()` to learn a vocabulary from `tweets` and store the resulting TF-IDF representation of `tweets` in the variable `tweets_tfidf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Write your code here\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=10, max_df=0.8)  # DO NOT MODIFY THIS LINE\n",
    "tweets_tfidf = vectorizer.fit_transform(tweets)\n",
    "\n",
    "# -- End of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1031)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart ii. [2 points]** What is the size of vocabulary learned by the `TfidfVectorizer` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1031\n"
     ]
    }
   ],
   "source": [
    "# -- Write your code here\n",
    "vocab_size = tweets_tfidf.shape[1]  # find the size of the vocabulary\n",
    "# -- End of your code\n",
    "\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iii. [2 points]** Which column of `tweets_tfidf` represents the word \"disaster\"? (Hint: What is the index of word \"disaster\"?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'disaster' corresponds to column 275\n"
     ]
    }
   ],
   "source": [
    "# -- Write your code here\n",
    "disaster_index =  vectorizer.vocabulary_['disaster'] # find the index of the word \"disaster\"\n",
    "# -- End of your code\n",
    "\n",
    "\n",
    "print(\"The word 'disaster' corresponds to column\", disaster_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) [30 points across subparts]** We now try to understand how keywords appear in tweets.\n",
    "\n",
    "**Subpart i. [4 points]** We begin by loading in some keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "# Run this cell to load the keywords\n",
    "\n",
    "keywords = np.load('mystery_red.npy')\n",
    "print(len(keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variable `keywords` and `tweets` have the same length and in fact are ordered the same way, i.e., the i-th keyword corresponds to the i-th tweet (put another way, we have assigned each tweet to a single keyword).\n",
    "\n",
    "Let's focus on 2 keywords: \"earthquake\" and \"drought\". Store the tweets of these two keywords separately in two lists (i.e., each list should consist of strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Write your code here\n",
    "earthquake_tweets = [tweet for tweet,keyword in zip(tweets, keywords) if keyword=='earthquake']\n",
    "drought_tweets = [tweet for tweet,keyword in zip(tweets, keywords) if keyword=='drought']\n",
    "# -- End of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thx for your great encouragement and for rt of new video the coming apocalyptic us earthquake amp tsunami'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquake_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 25\n"
     ]
    }
   ],
   "source": [
    "print(len(earthquake_tweets),len(drought_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart ii. [14 points]** We next try to see whether tweets with the keyword \"earthquake\" somehow appear different from tweets with the keyword \"drought\". One basic way to do this is to look at the top words for tweets with the keyword \"earthquake\", and compare to the top words for tweets with the keyword \"drought\".\n",
    "\n",
    "Specifically, for the tweets with keyword \"earthquake\", fit a `CountVectorizer` object to these tweets with a single argument `stop_words=\"english\"` (**do not use any other arguments**). List the top 5 most frequent words that appear among these tweets (in particular, for each word, we define it's frequency to be the sum of its raw count frequencies across all tweets with keyword \"earthquake\"----this is precisely just the collection term frequency of the word as a raw count, where the collection is taken to be all tweets with keyword \"earthquake\"). When you list the top 5 words, for each word, also print out its corresponding collection term frequency (again, the collection is all tweets with keyword \"earthquake\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 190)\n",
      "=== Earthquake ===\n",
      "rank  0 :  palms\n",
      "Collection term frequency is  25\n",
      "rank  1 :  bb17\n",
      "Collection term frequency is  9\n",
      "rank  2 :  07\n",
      "Collection term frequency is  7\n",
      "rank  3 :  175225\n",
      "Collection term frequency is  7\n",
      "rank  4 :  fox\n",
      "Collection term frequency is  5\n"
     ]
    }
   ],
   "source": [
    "earthquake_vectorizer = CountVectorizer(stop_words=\"english\")  # DO NOT MODIFY\n",
    "\n",
    "# -- Write your code here\n",
    "earthquake_term_frequencies = earthquake_vectorizer.fit_transform(earthquake_tweets)\n",
    "print(earthquake_term_frequencies.shape)\n",
    "\n",
    "earth_word_freq = earthquake_term_frequencies.sum(axis=0)\n",
    "earth_word_freq=np.array([earth_word_freq[0,i] for i in range(earthquake_term_frequencies.shape[1])])\n",
    "\n",
    "top_indices = np.argsort(-earth_word_freq)[:5]\n",
    "word_list_earth = list(earthquake_vectorizer.vocabulary_.keys())\n",
    "\n",
    "# code here to figure out each vocabulary word's collection term frequency across tweets with keyword \"earthquake\"\n",
    "\n",
    "print(\"=== Earthquake ===\")\n",
    "# print the top 5 words and their collection term frequencies\n",
    "for rank,index in enumerate(top_indices):\n",
    "    print(\"rank \",rank,\": \",word_list_earth[index])\n",
    "    print(\"Collection term frequency is \", sorted(earth_word_freq,reverse=True)[rank])\n",
    "    \n",
    "# -- End of your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the above code cell but now for tweets with the keyword \"drought\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 134)\n",
      "=== Drought ===\n",
      "rank  0 :  californians\n",
      "Collection term frequency is  23\n",
      "rank  1 :  river\n",
      "Collection term frequency is  4\n",
      "rank  2 :  scared\n",
      "Collection term frequency is  4\n",
      "rank  3 :  27\n",
      "Collection term frequency is  3\n",
      "rank  4 :  major\n",
      "Collection term frequency is  3\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THE NEXT LINE\n",
    "drought_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# -- Write your code here\n",
    "drought_term_frequencies = drought_vectorizer.fit_transform(drought_tweets)\n",
    "print(drought_term_frequencies.shape)\n",
    "\n",
    "drought_word_freq = drought_term_frequencies.sum(axis=0)\n",
    "drought_word_freq=np.array([drought_word_freq[0,i] for i in range(drought_term_frequencies.shape[1])])\n",
    "\n",
    "top_indices2 = np.argsort(-drought_word_freq)[:5]\n",
    "word_list_drought = list(drought_vectorizer.vocabulary_.keys())\n",
    "\n",
    "# code here to figure out each vocabulary word's collection term frequency across tweets with keyword \"drought\"\n",
    "\n",
    "print(\"=== Drought ===\")\n",
    "# print the top 5 words and their collection term frequencies\n",
    "# (now the collection is across tweets with keyword \"drought\" and not \"earthquake\"!)\n",
    "for rank,index in enumerate(top_indices2):\n",
    "    print(\"rank \",rank,\": \",word_list_drought[index])\n",
    "    print(\"Collection term frequency is \", sorted(drought_word_freq,reverse=True)[rank])\n",
    "# -- End of your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remark: If you've been paying close attention, you might have realized that this problem is essentially a cluster interpretation problem. Each tweet has been assigned to a cluster corresponding to a specific keyword, and we are trying to interpret two different clusters (one for \"earthquake\" and one for \"drought\") by viewing each of them as a collection of texts and applying ideas we have seen previously in the course. For this problem, the cluster assignments are given to you, but in many real-world applications (not in this quiz), you might need to automatically come up with the cluster assignments.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iii (no coding). [2 points]** According to the answer from the previous subpart, do the most frequent words make sense? Are they related to the keyword?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer (no coding):\n",
    "\n",
    "The most frequent words in earthquake seem confusing. Palms are plant and fox is an animal. Others make no sense if no context is given. Maybe more background information needs to be provided.\n",
    "\n",
    "As for in drought, the top3 are somewhat related, maybe californians have some relation to drought research, and river and scared emotion are also related terms. Major may indicate the drought is a major disaster. But 27 cannot be intepreted without background info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iv. [10 points]** It turns out that there are labels available for whether a tweet corresponds to a real disaster or not. We next load in these labels. The labels have two values `0` and `1`. `0` means that a tweet is about a fake disaster, whereas `1` means that a tweet is about a real disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "# Run this cell to load the labels\n",
    "\n",
    "labels = np.load(\"mystery_logo.npy\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `labels` and `tweets` are in the same order, i.e., `labels[i]` is the label for `tweets[i]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, each keyword corresponds to a collection of tweets. For a specific keyword, we define its **\"real disaster ratio\"** as the fraction of tweets corresponding to the keyword that have label `1`.\n",
    "\n",
    "List the top 5 keywords that have the highest real disaster ratio, and the bottom 5 keywords that have the lowest real disaster ratio. Besides the keyword, please also print out the corresponding real disaster ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top 5 keywords ===\n",
      "debris :  1.0\n",
      "derailment :  1.0\n",
      "suicide bombing :  1.0\n",
      "wreckage :  1.0\n",
      "outbreak :  0.9705882352941176\n",
      "=== Bottom 5 keywords ===\n",
      "aftershock :  0.0\n",
      "body bag :  0.0\n",
      "ruin :  0.03125\n",
      "screaming :  0.03125\n",
      "body bags :  0.034482758620689655\n",
      "Real disaster ratio:  0.4171666666666667\n"
     ]
    }
   ],
   "source": [
    "# -- Write your code here\n",
    "real_disaster_ratio = (labels==1).sum()/len(labels)\n",
    "# some code goes here\n",
    "keywords_filtered = keywords[labels==1]\n",
    "tweets_filtered = tweets[labels==1]\n",
    "\n",
    "counter = {}\n",
    "print(\"=== Top 5 keywords ===\")\n",
    "# print out the top 5 keywords with the highest real disaster ratios\n",
    "for k in np.unique(keywords):\n",
    "    keyword_tweets = [tweet for tweet,keyword,label in zip(tweets, keywords, labels) if keyword==k]\n",
    "    keyword_tweets2 = [tweet for tweet,keyword,label in zip(tweets, keywords, labels) if keyword==k and label==1]\n",
    "    ratio = len(keyword_tweets2)/len(keyword_tweets)\n",
    "    counter[k]=ratio\n",
    "for keyword,value in sorted(counter.items(),reverse=True,key=lambda x:x[1])[:5]:\n",
    "    print(keyword,\": \",value)\n",
    "\n",
    "print(\"=== Bottom 5 keywords ===\")\n",
    "# print out the bottom 5 keywords with the highest real disaster ratios\n",
    "for keyword,value in sorted(counter.items(),key=lambda x:x[1])[:5]:\n",
    "    print(keyword,\": \",value)\n",
    "\n",
    "print(\"Real disaster ratio: \",real_disaster_ratio)\n",
    "# -- End of your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) [16 points across subparts]** Let's look at a prediction task. Specifically, we examine a model that, given a tweet, predicts whether the tweet corresponds to a real disaster or not (i.e., in the latter, the tweet is just about a fake disaster).\n",
    "\n",
    "In part **(a)-i**, we asked you to calculate TF-IDF representations of tweets and store them in the variable `tweets_tfidf`. Even if you did not complete this part, you will still be able to do this problem. What we have done behind the scenes is, for a correctly computed version of `tweets_tfidf`, we trained a classifier on these TF-IDF feature vectors to predict the labels that are mentioned in part **(b)-iv** (you also do not need to have done part **(b)** to answer this part). To answer this part, you don't need to know the precise details of the mystery classifier we used.\n",
    "\n",
    "We then used our mystery classifier to predict on a held-out test set of tweets (stored in `test_tweets` below). In particular, the classifier computes a predicted probability of class 0 (fake disaster) as well as a predicted probability of class 1 per test tweet. These predicted probabilities are stored in the variable `test_tweet_pred_prob` below. The true test set labels are in the variable `test_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "# Run this cell to load test data information\n",
    "\n",
    "test_tweets = np.load('mystery_lighthouse.npy')\n",
    "test_tweet_pred_prob = np.load('mystery_kangaroos.npy')\n",
    "test_labels = np.load('mystery_willunga.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the 0-th test tweet is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the first year the forest service spent more than half its annual budget on fighting fires climatechange'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "test_tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probability of this tweet being about a real disaster is 0.9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.9])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "test_tweet_pred_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858 858\n"
     ]
    }
   ],
   "source": [
    "print(len(test_tweets),len(test_tweet_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The subparts below can be done in any order.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart i (no coding). [4 points]** During training, we had constructed a vocabulary from the training data as one of the key steps (specifically, we used a TF-IDF representation; to use this representation, we needed to build a vocabulary and weight each vocabulary word based on some notion of inverse document frequency). Once we have completely trained our classifier, at the time of prediction, do we fit another `TfidfVectorizer` to the test tweets to come up with feature vectors for use with the already-trained classifier? Please clearly state \"yes\" or \"no\", and be sure to explain your answer. Correctly specifying \"yes\" or \"no\" without a correct explanation will not receive full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here, including an explanation (no coding):\n",
    "\n",
    "No, we need to use the same fitted vectorizer, since that is the topic modelling we learned from train data. If we fit another vectorizer with test tweets, then it does not match the classifier we will use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart ii (no coding). [4 points]** Briefly explain why it does not make sense during training to fit a `TfidfVectorizer` object (or a `CountVectorizer` object) on a complete dataset that includes both the training data *and* test data (where the test data are what we will ultimately evaluate the accuracy of the prediction model on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your explanation here (no coding):\n",
    "\n",
    "If we fit the vectorizer on the entire set, then the information from test set is also learned and included during the training process. Then our test set is no longer another dataset to apply test on. This will lead to overestimate the accuracy of our model, since the model already learns the test set to some degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iii. [8 points]** Let's try to understand what words commonly appear in tweets that are highly likely (according to the learned mystery classifier) about real disasters. To do this, write code that:\n",
    "\n",
    "- determines the test set tweets that have predicted probability of real disaster at least 0.9; denote these test set tweets as `test_set_tweets_likely_real_disaster`\n",
    "- treating `test_set_tweets_likely_real_disaster` as a collection of text documents, compute the collection term frequencies of the different terms encountered (to do this, build a vocabulary using `CountVectorizer`, initialized with a single argument `stop_words=\"english\"` and no other arguments)\n",
    "- prints out the top 10 words with the highest collection term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_tweet_pred_prob[:,1]>=0.9).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top 10 words ===\n",
      "(118, 610)\n",
      "rank  0 :  child\n",
      "Collection term frequency is  14\n",
      "rank  1 :  way\n",
      "Collection term frequency is  8\n",
      "rank  2 :  philippines\n",
      "Collection term frequency is  8\n",
      "rank  3 :  accident\n",
      "Collection term frequency is  8\n",
      "rank  4 :  idfire\n",
      "Collection term frequency is  8\n",
      "rank  5 :  hostage\n",
      "Collection term frequency is  8\n",
      "rank  6 :  killing\n",
      "Collection term frequency is  8\n",
      "rank  7 :  2781\n",
      "Collection term frequency is  7\n",
      "rank  8 :  mt\n",
      "Collection term frequency is  7\n",
      "rank  9 :  pamela\n",
      "Collection term frequency is  6\n"
     ]
    }
   ],
   "source": [
    "# -- Write your code here\n",
    "\n",
    "test_set_tweets_very_likely_real_disaster = test_tweets[test_tweet_pred_prob[:,1]>=0.9]\n",
    "\n",
    "print(\"=== Top 10 words ===\")\n",
    "vectorizer_new = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# -- Write your code here\n",
    "term_frequencies = vectorizer_new.fit_transform(test_set_tweets_very_likely_real_disaster)\n",
    "print(term_frequencies.shape)\n",
    "\n",
    "word_freq_new = term_frequencies.sum(axis=0)\n",
    "word_freq_new=np.array([word_freq_new[0,i] for i in range(term_frequencies.shape[1])])\n",
    "\n",
    "top_indices3 = np.argsort(-word_freq_new)[:10]\n",
    "word_list_new = list(vectorizer_new.vocabulary_.keys())\n",
    "\n",
    "for rank,index in enumerate(top_indices3):\n",
    "    print(\"rank \",rank,\": \",word_list_new[index])\n",
    "    print(\"Collection term frequency is \", sorted(word_freq_new,reverse=True)[rank])\n",
    "\n",
    "# -- End of your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

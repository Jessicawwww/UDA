{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d056e3ab",
   "metadata": {},
   "source": [
    "# CMU 95-865 - Unstructured Data Analytics Spring 2022 Quiz 1\n",
    "\n",
    "**Make sure your Zoom video is on and that you can see/hear the course staff.**\n",
    "\n",
    "This is an 80 minute exam. We will only grade what is submitted via Canvas.\n",
    "\n",
    "You must fill in your name and your Andrew ID for this quiz to be graded. Moreover, filling out your name and Andrew ID below will serve as your agreement with us, the course staff, that you did not collaborate with anyone on this exam and that what you submit is truly your own individual work and not that of anyone else. Violations found will result in severe penalties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759235e5",
   "metadata": {},
   "source": [
    "Your name: solutions\n",
    "\n",
    "Your Andrew ID: n/a\n",
    "\n",
    "**Warning: If you leave the above blank, your quiz will not be graded.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861df87a",
   "metadata": {},
   "source": [
    "**Important:** There are 2 problems that can be done in either order. The first problem has no coding. The second problem is mostly on coding with a few non-coding interpretation parts. The second problem has 3 parts (a), (b), and (c) that can be done in any order.\n",
    "\n",
    "**Throughout the coding problem, do not import any additional packages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf5e73",
   "metadata": {},
   "source": [
    "## Problem 1: Co-occurrence analysis (no coding) [30 points]\n",
    "\n",
    "*Please do not answer any parts of this problem with code.*\n",
    "\n",
    "Suppose that we have a collection of text documents, and that someone has already run named entity recognition on each of the documents and found the following named enties (per document, we list the named entities found as a length-2 tuple of the format \"(named entity, named entity label)\"):\n",
    "\n",
    "- Document 1: (Alejandro Giammattei, PERSON)\n",
    "- Document 2: (Pope Francis, PERSON)\n",
    "- Document 3: (Boris Johnson, PERSON)\n",
    "- Document 4: (Volodymyr Zelensky, PERSON), (Ukraine, GPE)\n",
    "- Document 5: (Fumio Kishida, PERSON), (Japan, GPE), (Yoshihide Suga, PERSON)\n",
    "\n",
    "Each time a named entity appeared in a document, the named entity appeared exactly once.\n",
    "\n",
    "**(a) [10 points across subparts]** As we discussed in lecture, there are different ways that one can construct a co-occurrence table.\n",
    "\n",
    "**Subpart i. [5 points]** Let's first compute a co-occurrence table as follows: count the number of documents that mention both a specific PERSON and a specific GPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a38ce",
   "metadata": {},
   "source": [
    "**Your answer here (fill out the table below; note that rows index people and columns index geopolitical entities)**:\n",
    "\n",
    "| <i></i>              | Ukraine | Japan |\n",
    "| -------------------- |:-------:|:-----:|\n",
    "| Alejandro Giammattei | 0       | 0     |\n",
    "| Pope Francis         | 0       | 0     |\n",
    "| Boris Johnson        | 0       | 0     |\n",
    "| Volodymyr Zelensky   | 1       | 0     |\n",
    "| Fumio Kishida        | 0       | 1     |\n",
    "| Yoshihide Suga       | 0       | 1     |\n",
    "\n",
    "There isn't really much of an explanation needed for this subpart as it is straightforward. We get the numbers above by counting the number of documents that mention the specific person of interest and Ukraine/Japan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614bd9d",
   "metadata": {},
   "source": [
    "**Subpart ii. [5 points]** For each of the nonzero counts in your co-occurrence table that you computed in **subpart i**, suppose that we create flashcards (1 per co-occurrence that you counted). For instance, if Pope Francis and Ukraine co-occurred 3 times, then we would create 3 flashcards that say \"Pope Francis, Ukraine\". We put these flashcards into a bag. What is the probability of drawing a flashcard that says \"Yoshihide Suga, Japan\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b307e",
   "metadata": {},
   "source": [
    "**Your answer here:** There are a total of 3 flashcards: \"Volodymyr Zelensky, Ukraine\", \"Fumio Kishida, Japan\", and \"Yoshihide Suga, Japan\". Assuming that these occur with equal probability, then drawing the flashcard that says \"Yoshihide Suga, Japan\" happens with probability 1/3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e172cbc8",
   "metadata": {},
   "source": [
    "**(b) [15 points across subparts]** (This part does **not** depend on part **(a)**.) Let's consider a different setup from part **(a)**. Suppose that we put documents 1, 2, 3, 4, and 5 into a bag, where drawing any document out of the bag has equal probability (i.e., drawing each document has probability 1/5).\n",
    "\n",
    "**Subpart i. [5 points]**  What is the probability that you draw a document in which Yoshihide Suga and Japan co-occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4009c69",
   "metadata": {},
   "source": [
    "**Your answer here:** Yoshihide Suga and Japan only co-occur in document 5. Drawing document 5 out of the bag happens with probability 1/5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d61d0",
   "metadata": {},
   "source": [
    "**Subpart ii. [5 points]** Suppose that we compute PMI as follows:\n",
    "\n",
    "- Let x = probability of drawing a document from the bag in which named entities A and B both occur.\n",
    "- Let y = probability of drawing a document from the bag in which named entity A occurs.\n",
    "- Let z = probability of drawing a document from the bag in which named entity B occurs.\n",
    "- Let the PMI be given by log(x / (y * z)).\n",
    "\n",
    "Using the above steps, what is the PMI of Yoshihide Suga and Japan? (Note: leave the base of the log unspecified, i.e., if you think x = 1, y = 1, and z = 1/10, then leave your answer in the form \"log(10)\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d31c0d",
   "metadata": {},
   "source": [
    "**Your answer here:** Setting A = Yoshihide Suga and B = Japan, then note that **subpart i** says that x = 1/5.\n",
    "\n",
    "In this case, y and z are each also equal to the probability of drawing document 5.\n",
    "\n",
    "Thus x / (y * z) = (1/5) / ((1/5) * (1/5)) = 5.\n",
    "\n",
    "Thus, the PMI of Yoshihide Suga and Japan is given by log(5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e68edf",
   "metadata": {},
   "source": [
    "**Subpart iii. [5 points]** Using the same way to calculate PMI as stated in **subpart ii**, what is the PMI of Boris Johnson and Ukraine?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6dd02e",
   "metadata": {},
   "source": [
    "**Your answer here:** Boris Johnson and Ukraine don't co-occur, so the probability of then co-occurring is 0. (If you then just say that this implies that the PMI is either negative infinity or undefined, we award full credit. However, in the solutions here, we provide a more detailed explanation.)\n",
    "\n",
    "Meanwhile, the probability of drawing a document that mentions Boris Johnson and, separately, the probability of drawing a document that mentions Ukraine are both positive (in fact they are both equal to 1/5).\n",
    "\n",
    "Thus, the PMI in this case is given by log(0 / ((1/5) * (1/5))) = log(0) which is negative infinity (we will also accept an answer of \"undefined\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665a385",
   "metadata": {},
   "source": [
    "**(c) [5 points]** (This part depends on parts **(a)** (both subparts) and **(b)-subpart i**.) In problem **(a)-subpart ii**, we saw one way to compute the probability in which Yoshihide Suga and Japan co-occur. In problem **(b)-subpart i**, we saw another way to compute the probability in which Yoshihide Suga and Japan co-occur. Briefly explain why the answers that we get are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468a848",
   "metadata": {},
   "source": [
    "**Your answer here:** We had set up two different probability models. In part **(a)**, we sample from a collection of co-occurrences. In part **(b)**, we are sampling the documents themselves.\n",
    "\n",
    "This problem is meant to emphasize this idea that when we say something like \"the probability of A and B co-occurring\", we do have to be clear about what the probability model is that we are working with. Sometimes it is intuitively obvious, but often times it is not!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db1691",
   "metadata": {
    "id": "31db1691"
   },
   "source": [
    "## Problem 2: What quiz questions are in Jeopardy? (coding, with a very brief non-coding component at the very end) [70 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e545d0",
   "metadata": {},
   "source": [
    "**Warning:** Throughout this problem, we import packages for you. Do **not** import any additional packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd7226",
   "metadata": {
    "id": "7ccd7226"
   },
   "source": [
    "**Jeopardy!** is an American television game show created by Merv Griffin. The show features a quiz competition in which contestants are presented with general knowledge clues in the form of answers, and must phrase their responses in the form of questions.\n",
    "\n",
    "In this problem, we analyze a curated set of questions from Jeopardy. We begin by loading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2128522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 2588\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "def read_text_file(filename):\n",
    "    with open(filename, 'r', encoding='utf8') as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "questions = read_text_file('mystery_corn_flakes.txt')\n",
    "categories = read_text_file('mystery_blackjack.txt')\n",
    "answers = read_text_file('mystery_justice.txt')\n",
    "print('Number of questions:', len(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3325b4",
   "metadata": {},
   "source": [
    "Note that the i-th question corresponds to the i-th category and to the i-th answer. For instance, `questions[0]` is about the category `categories[0]` and has an answer given by `answers[0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0aeb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\n",
      "Category: HISTORY\n",
      "Answer: Copernicus\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "print('Question:', questions[0])\n",
    "print('Category:', categories[0])\n",
    "print('Answer:', answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02925bb",
   "metadata": {},
   "source": [
    "**Please run the cell below before doing anything else for this problem since it can take a little bit of time to run (for us it takes around 1-2 minutes but possibly it can take a bit longer on your machine).** This cell creates a variable `parsed_questions`, which contains spacy Doc objects, one per question in `questions`. In particular, the spacy Doc corresponding to `questions[i]` is `parsed_questions[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fe6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])\n",
    "parsed_questions = [nlp(q) for q in questions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade21144",
   "metadata": {},
   "source": [
    "**Warning:** Do **not** modify the variable `parsed_questions`. It is used in different parts of the problem and if you accidentally modify it, you would have to re-run the above cell.\n",
    "\n",
    "**This problem has been written so that parts (a), (b), and (c) can be done in any order.** For example, if you get stuck on part (b), you can skip over to doing part (c). However, within each of these three parts, the subparts can depend on each other. The first part (a) has no subparts and is intentionally shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edca3c",
   "metadata": {},
   "source": [
    "**(a) [10 points]** From one of the code cells we provided above, you should've seen that Copernicus is the answer to the 0-th question \"For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\". One can check that the string `\"Copernicus\"` does *not* actually appear anywhere in the questions in the dataset that we loaded in (in other words, no string in the list `questions` contains the substring `\"Copernicus\"`).\n",
    "\n",
    "Write code to determine the fraction of the strings in `answers` that can be found in **any strings** of questions. **Each element in the answers list is considered as one string. Your code should not split any strings by spaces.** For instance, suppose that `answers` consisted of three strings `\"Marie Curie\"`, `\"Nikola Tesla\"`, and `\"Sandro Botticelli\"`. If `\"Marie Curie\"` is contained in at least one of the strings in `questions`, but `\"Nikola Tesla\"` and `\"Sandro Botticelli\"` are *not* contained in any of the strings in `questions`, then the answer to this question would be 1/3. **For simplicity, do not convert any of the text to lowercase or uppercase--leave the casing the same and check for matches in a case-sensitive manner.**\n",
    "\n",
    "Hint: To see if the string `x` is in another string `y`, you can use the boolean expression `x in y`. For instance, `'Galileo' in questions[0]` returns `True` (indeed, `'Galileo'` is a substring contained in `questions[0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c022c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of answers that are contained in questions: 0.303323029366306\n"
     ]
    }
   ],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "found_matches = 0\n",
    "for answer in answers:\n",
    "    for question in questions:\n",
    "        if answer in question:\n",
    "            found_matches += 1\n",
    "            break  # we do a break here since there is at this point no need to check any other Jeopardy questions! otherwise, you could double count\n",
    "# <------------------- END OF YOUR CODE --------------------------->\n",
    "\n",
    "# DO NOT MODIFY THE LINE BELOW\n",
    "print('Fraction of answers that are contained in questions:', found_matches / len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18498b74",
   "metadata": {},
   "source": [
    "*It turns out that most answers cannot be found in the questions, meaning that with only access to the questions (and not the answers) and no other datasets, we really can't hope to answer most of the questions!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbedfa7",
   "metadata": {},
   "source": [
    "**Alternate solution:** There are other ways you could have coded this problem up. Here's a one-liner (the basic strategy is to: (step 1) per answer, sum up the number of questions that contain that answer, and (step 2) sum up the number of answers for which the number of questions that contain the answer is at least 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef56e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of answers that are contained in questions: 0.303323029366306\n"
     ]
    }
   ],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "found_matches = np.sum(np.sum([[1*(answer in question) for question in questions] for answer in answers], axis=1) >= 1)\n",
    "# <------------------- END OF YOUR CODE --------------------------->\n",
    "\n",
    "# DO NOT MODIFY THE LINE BELOW\n",
    "print('Fraction of answers that are contained in questions:', found_matches / len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a55aa3",
   "metadata": {},
   "source": [
    "**Alternate solution with a different final answer:** We also accepted the following different interpretation of the problem that iterates only through the unique answers (as to avoid double counting any answer --- it does require modifying the line after \"DO NOT MODIFY THE LINE BELOW\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1295d67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of answers that are contained in questions: 0.2356717102246676\n"
     ]
    }
   ],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "found_matches = 0\n",
    "for answer in set(answers):\n",
    "    for question in questions:\n",
    "        if answer in question:\n",
    "            found_matches += 1\n",
    "            break  # we do a break here since there is at this point no need to check any other Jeopardy questions! otherwise, you could double count\n",
    "# <------------------- END OF YOUR CODE --------------------------->\n",
    "\n",
    "# DO NOT MODIFY THE LINE BELOW\n",
    "print('Fraction of answers that are contained in questions:', found_matches / len(set(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d99a18",
   "metadata": {
    "id": "43d99a18"
   },
   "source": [
    "**(b)** Many questions in the dataset involve dates. Does Jeopardy tend to favor particular dates in terms of the questions asked? To answer this, we focus just on *years* rather than specific dates that include months or days.\n",
    "\n",
    "**Subpart i. [8 points]** For each question in the dataset, look for named entities with the label `'DATE'` and that have string representations that are each exactly 4 characters long and consist only of digits---we shall assume that named entities satisfying these conditions correspond to years. Create a histogram `year_counter` (that is a `Counter` instance) that counts how often each year appears. **Important**: Your `year_counter` should have each key/value pair correspond to a year (integer)/raw count frequency (integer) pair.\n",
    "\n",
    "Note: in writing your code, please make use of the `parsed_questions` variable that we defined at the start of Problem 2 (that involves spaCy doing the parsing of the different questions). You should *not* have to re-run spaCy parsing!\n",
    "\n",
    "Hint: if the variable `x` is a string, then `x.isdigit()` checks whether `x` consists of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3551cf6b",
   "metadata": {
    "id": "3551cf6b"
   },
   "outputs": [],
   "source": [
    "year_counter = Counter()  # do not change this line; your code below should populate `year_counter`\n",
    "\n",
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "for parsed in parsed_questions:\n",
    "    for ent in parsed.ents:\n",
    "        ent_str = str(ent)\n",
    "        if (ent.label_ == \"DATE\") and len(ent_str) == 4 and ent_str.isdigit():\n",
    "            year_counter[int(ent_str)] += 1\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ddb66",
   "metadata": {},
   "source": [
    "**Alternate solution:** We don't really know of how to write the code in a more straightforward manner than what we've written above. If you wanted a one-liner solution, it would still use essentially the same logic. Here's a one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607c7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counter = Counter()  # do not change this line; your code below should populate `year_counter`\n",
    "\n",
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "year_counter.update([int(str(ent)) for parsed in parsed_questions for ent in parsed.ents if (ent.label_ == \"DATE\") and len(str(ent)) == 4 and str(ent).isdigit()])\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04ef44",
   "metadata": {},
   "source": [
    "In fact the above cell could be made even shorter if we just write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f1d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counter = Counter([int(str(ent)) for parsed in parsed_questions for ent in parsed.ents if (ent.label_ == \"DATE\") and len(str(ent)) == 4 and str(ent).isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a97b81",
   "metadata": {},
   "source": [
    "**Subpart ii. [4 points]** spaCy's named entity recognition isn't always accurate. Let's do a quick sanity check. What are the minimum and maximum years that you found (stored in `year_counter`)? To answer this question, write code that prints out the minimum and maximum years found. Note that we are asking about minimum as in earliest in time, and maximum as it latest in time----we are **not** asking about minimum as in least frequent and maximum as in most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7970b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year found: 1025\n",
      "Max year found: 3001\n"
     ]
    }
   ],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "min_year_found = min(year_counter.keys())\n",
    "max_year_found = max(year_counter.keys())\n",
    "# <------------------- END OF YOUR CODE --------------------------->\n",
    "\n",
    "# DO NOT MODIFY THE CODE BELOW\n",
    "print('Min year found:', min_year_found)\n",
    "print('Max year found:', max_year_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71348cb1",
   "metadata": {},
   "source": [
    "**Subpart iii. [6 points]** Write code that finds and prints out all questions that contain a named entity corresponding to the minimum year found, and separately all questions that contain a named entity corresponding to the maximum year found. (These named entities should use the same filters as in **subpart i** to determine whether they are considered a year or not.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7414eb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question(s) containing the minimum year found]\n",
      "In 1025 Boleslaw I became this country's first king but died within the year\n",
      "\n",
      "[Question(s) containing the maximum year found]\n",
      "He wrote the \"2001\", \"2010\", \"2061\" & \"3001\" Odyssey books\n"
     ]
    }
   ],
   "source": [
    "print('[Question(s) containing the minimum year found]')  # DO NOT MODIFY THIS LINE\n",
    "\n",
    "# <------ YOUR CODE HERE FOR PRINTING OUT QUESTION(S) CONTAINING THE MINIMUM YEAR FOUND ------>\n",
    "# note that this code is actually largely just a copy and paste of the solution to subpart i, slightly modified\n",
    "for question, parsed in zip(questions, parsed_questions):\n",
    "    for ent in parsed.ents:\n",
    "        ent_str = str(ent)\n",
    "        if (ent.label_ == \"DATE\") and len(ent_str) == 4 and ent_str.isdigit():\n",
    "            if int(ent_str) == min_year_found:\n",
    "                print(question)\n",
    "                break  # we do a break here since there's no need to print the Jeopardy question more than once if the year appears a second time in the same question\n",
    "# <------ END OF YOUR CODE FOR PRINTING OUT QUESTION(S) CONTAINING THE MINIMUM YEAR FOUND ---->\n",
    "\n",
    "\n",
    "print(\"\\n[Question(s) containing the maximum year found]\")  # DO NOT MODIFY THIS LINE\n",
    "\n",
    "# <------ YOUR CODE HERE FOR PRINTING OUT QUESTION(S) CONTAINING THE MAXIMUM YEAR FOUND ------>\n",
    "# this code is the same as the one for the minimum year where we replace `min_year_found` with `max_year_found`\n",
    "for question, parsed in zip(questions, parsed_questions):\n",
    "    for ent in parsed.ents:\n",
    "        ent_str = str(ent)\n",
    "        if (ent.label_ == \"DATE\") and len(ent_str) == 4 and ent_str.isdigit():\n",
    "            if int(ent_str) == max_year_found:\n",
    "                print(question)\n",
    "                break  # we do a break here since there's no need to print the Jeopardy question more than once if the year appears a second time in the same question\n",
    "# <------ END OF YOUR CODE FOR PRINTING OUT QUESTION(S) CONTAINING THE MAXIMUM YEAR FOUND ---->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709e492",
   "metadata": {},
   "source": [
    "*Different versions of spaCy can detect different named entities a bit differently. We'll just say that when we run this, the minimum and maximum years actually do correspond to years and aren't errors in named entity recognition (although perhaps you get a different result).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb063068",
   "metadata": {
    "id": "cb063068"
   },
   "source": [
    "**Subpart iv. [6 points]** Plot a histogram showing years 1900 to 2000 (including both 1900 and 2000) of the year counter. The x axis (corresponding to years) should be in chronological order. Be sure to label your x-axis and y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8af30b69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "8af30b69",
    "outputId": "ea3f2ef8-6c3f-463a-acf4-32d67ded2504"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "x_values = sorted([i for i in year_counter.keys() if i >= 1900 and i <= 2000])\n",
    "x_label = range(len(x_values))\n",
    "y_values = [year_counter[year] for year in x_values]\n",
    "plt.bar(x_label, y_values)\n",
    "plt.xticks(x_label, x_values)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3caa2",
   "metadata": {},
   "source": [
    "What do you observe? Are there any specific years which are immensely popular or is the distribution well spread out?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e062384",
   "metadata": {
    "id": "0e062384"
   },
   "source": [
    "**Your answer here**: The years in questions are quite diversified/spread out. A handful of years were frequently asked such as 1929, 1975, and 1912."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f41cb7",
   "metadata": {
    "id": "64f41cb7"
   },
   "source": [
    "**(c)** In this part, we try to understand how questions in the category `\"WORLD HISTORY\"` differ from the ones in the category `\"LITERATURE\"`. We shall do this using both frequency analysis and dimensionality reduction.\n",
    "\n",
    "**Subpart i. [4 points]** Write code that obtains the subset of `questions`, `parsed_questions`, and `categories` for which `categories` is either `\"WORLD HISTORY\"` or `\"LITERATURE\"`. Store the resulting subsets in the variables `subset_questions`, `subset_parsed_questions`, and `subset_categories` respectively (so that `subset_questions[i]` has category given by `subset_categories[i]`, which should always be either `\"WORLD HISTORY\"` or `\"LITERATURE\"`, and the spaCy-parsed version of `subset_questions[i]` is in `subset_parsed_questions[i]`). You should *not* have to re-run spaCy parsing!\n",
    "\n",
    "Note that for this part, we will not use the `answers` variable.\n",
    "\n",
    "If your code works correctly, then `len(subset_questions)` should equal 873."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278929ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "subset_questions = [question for question, category in zip(questions, categories) if category == \"WORLD HISTORY\" or category == \"LITERATURE\"]\n",
    "subset_categories = [category for category in categories if category == \"WORLD HISTORY\" or category == \"LITERATURE\"]\n",
    "subset_parsed_questions = [parsed_question for parsed_question, category in zip(parsed_questions, categories) if category == \"WORLD HISTORY\" or category == \"LITERATURE\"]\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e36cf4",
   "metadata": {},
   "source": [
    "**Alternate solution:** Here's another solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1790e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "subset_questions = []\n",
    "subset_parsed_questions = []\n",
    "subset_categories = []\n",
    "for question, parsed_question, category in zip(questions, parsed_questions, categories):\n",
    "    if category == 'WORLD HISTORY' or category == 'LITERATURE':\n",
    "        subset_questions.append(question)\n",
    "        subset_parsed_questions.append(parsed_question)\n",
    "        subset_categories.append(category)\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03ca94",
   "metadata": {},
   "source": [
    "**Subpart ii. [10 points]** Let's now represent the questions as feature vectors. We first load in the vocabulary words that we will keep track of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "696f12e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "vocab = read_text_file('mystery_feather.txt')\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e8f97",
   "metadata": {},
   "source": [
    "We will only be keeping track of how often the words in `vocab` appear. In the code cell below, please write code that fills in the variable `term_frequency_table` (a 2D numpy array, where rows correspond to questions in the same order as they appear in `subset_questions` that you computed in **subpart i**, and columns correspond to the different vocabulary words in the same order as they appear in `vocab`).\n",
    "\n",
    "To fill in `term_frequency_table`, remember that the i-th row corresponds to a Jeopardy question `subset_questions[i]`, for which you already have the parsed version (a spacy Doc given by `subset_parsed_questions[i]`). Iterate through the tokens of this parsed spacy Doc, convert each token to lowercase (do not lemmatize) and if the lowercase token appears in `vocab`, then you increment the count for the lowercase token by 1 in the i-th row of `term_frequency_table` (you have to figure out what column index the token corresponds to).\n",
    "\n",
    "For example, suppose that `vocab[200]` is the word `\"early\"`. If `subset_questions[5]` were to correspond to a Jeopardy question for which the word `\"early\"` shows up 17 times (according to the tokens found by spaCy, converted to lowercase), then `term_frequency_table[5, 200]` would be equal to 17.  (Note that this is a made up example. `vocab[200]` is not actually equal to `\"early\"` and `subset_questions[5, 200]` is not actually equal to 17.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae6eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency_table = np.zeros((len(subset_questions), len(vocab)))\n",
    "\n",
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "for row_idx, parsed_question in enumerate(subset_parsed_questions):\n",
    "    for token in parsed_question:\n",
    "        token_str = token.orth_.lower()\n",
    "        if token_str in vocab:\n",
    "            col_idx = vocab.index(token_str)\n",
    "            term_frequency_table[row_idx, col_idx] += 1\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95433f4a",
   "metadata": {},
   "source": [
    "**Subpart iii. [4 points]** Unfortunately, using this term frequency representation, at least one question ends up getting represented as all 0's. Write code that prints out the question(s) that get represented as all 0's (i.e., these questions correspond to rows of `term_frequency_table` that are all 0's). Importantly, we are asking about printing the original question (from `subset_questions`) and *not* the raw counts representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed7ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaw's scorched saint\n"
     ]
    }
   ],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "for row, question in zip(term_frequency_table, subset_questions):\n",
    "    if row.sum() == 0:\n",
    "        print(question)\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20578d",
   "metadata": {},
   "source": [
    "**Subpart iv. [6 points]** Notice that if we look at only the rows of `term_frequency_table` that correspond to the category `\"WORLD HISTORY\"`, then if we sum across these rows, we actually get the overall term frequencies for `\"WORLD HISTORY\"` questions---this could be thought of as collection term frequencies, where the \"collection\" is the set of `\"WORLD HISTORY\"` questions. Using this idea, compute the collection term frequencies for `\"WORLD HISTORY\"` questions, and separately the collection term frequencies for `\"LITERATURE\"` questions. Then print out the top 10 words for each of these, along with their counts.\n",
    "\n",
    "In writing your code here, please work off of `term_frequency_table`. No credit will be given if you create a new histogram/`Counter` from scratch. As a reminder, please do not import any additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a3b3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top words for world history]\n",
      "country : 75.0\n",
      "king : 37.0\n",
      "war : 30.0\n",
      "city : 26.0\n",
      "battle : 19.0\n",
      "great : 18.0\n",
      "years : 18.0\n",
      "england : 15.0\n",
      "island : 15.0\n",
      "called : 13.0\n",
      "\n",
      "[Top words for literature]\n",
      "novel : 166.0\n",
      "title : 57.0\n",
      "wrote : 46.0\n",
      "author : 36.0\n",
      "published : 33.0\n",
      "book : 32.0\n",
      "character : 28.0\n",
      "story : 28.0\n",
      "work : 28.0\n",
      "tale : 27.0\n"
     ]
    }
   ],
   "source": [
    "# <------ YOUR CODE HERE TO COMPUTE THE COLLECTION TERM FREQUENCIES ------>\n",
    "ctf_world_history = term_frequency_table[np.array(subset_categories) == 'WORLD HISTORY'].sum(axis=0)\n",
    "ctf_literature = term_frequency_table[np.array(subset_categories) == 'LITERATURE'].sum(axis=0)\n",
    "# <------ END OF YOUR CODE TO COMPUTE THE COLLECTION TERM FREQUENCIES ---->\n",
    "\n",
    "\n",
    "\n",
    "print(\"[Top words for world history]\") # DO NOT MODIFY THIS LINE\n",
    "\n",
    "# <------ YOUR CODE HERE TO PRINT OUT THE TOP 10 WORDS ALONG WITH THEIR COUNTS FOR WORLD HISTORY ------------->\n",
    "for word, count in sorted(list(zip(vocab, ctf_world_history)), reverse=True, key=lambda x: x[1])[:10]:\n",
    "    print(word, ':', count)\n",
    "# <------ END OF YOUR CODE HERE TO PRINT OUT THE TOP 10 WORDS ALONG WITH THEIR COUNTS FOR WORLD HISTORY ------>\n",
    "\n",
    "\n",
    "print(\"\\n[Top words for literature]\") # DO NOT MODIFY THIS LINE\n",
    "\n",
    "# <------ YOUR CODE HERE TO PRINT OUT THE TOP 10 WORDS, ALONG WITH THEIR COUNTS FOR LITERATURE ------------>\n",
    "for word, count in sorted(list(zip(vocab, ctf_literature)), reverse=True, key=lambda x: x[1])[:10]:\n",
    "    print(word, ':', count)\n",
    "# <------ END OF YOUR CODE HERE TO PRINT OUT THE TOP 10 WORDS ALONG WITH THEIR COUNTS FOR LITERATURE ------>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cca7a0",
   "metadata": {},
   "source": [
    "**Subpart v. [12 points]** We now use dimensionality reduction to help visualize the data in 2D.\n",
    "\n",
    "First, we normalize the data. Specifically, we convert each question's raw count representation into fractional frequencies instead so that every question's feature vector's entries sum to 1 except for question's whose raw counts are all 0's. For just those cases, we leave their representation the same. Write code that computes this normalized representation and stores the resulting table in the variable `term_frequency_table_frac`. In particular, `term_frequency_table_frac` should be a 2D numpy table with the same shape as `term_frequency_table`; the i-th row of `term_frequency_table_frac` should correspond to the same underlying Jeopardy question as `term_frequency_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "227ce7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "term_frequency_table_frac = []\n",
    "for row in term_frequency_table:\n",
    "    row_sum = row.sum()\n",
    "    if row_sum > 0:\n",
    "        term_frequency_table_frac.append(row / row_sum)\n",
    "    else:\n",
    "        term_frequency_table_frac.append(row)\n",
    "term_frequency_table_frac = np.array(term_frequency_table_frac)\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee74132",
   "metadata": {},
   "source": [
    "**Alternate solution 1:** There are other ways you could have coded this up. Here's a one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ba2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "term_frequency_table_frac = np.array([row / ((row.sum() > 0) and row.sum() or 1) for row in term_frequency_table])\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd9af6",
   "metadata": {},
   "source": [
    "**Alternate solution 2:** Here's yet another way that uses fancier numpy functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d39308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "row_sum_nonzero_mask = (term_frequency_table.sum(axis=1) > 0)\n",
    "term_frequency_table_frac = term_frequency_table.copy()\n",
    "if np.any(row_sum_nonzero_mask):\n",
    "    term_frequency_table_frac[row_sum_nonzero_mask] /= term_frequency_table_frac[row_sum_nonzero_mask].sum(axis=1)[:, np.newaxis]\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdcc967",
   "metadata": {},
   "source": [
    "**Alternate solution 3:** For your amusement, we include this third alternate solution that is technically incorrect but gives an approximate answer that is close enough that in practice, people often won't care about the small error here. Note that many math functions in numpy/sklearn/torch actually do use these sorts of approximations as to make the code run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5787b691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation error in l2 distance: 5.112047028741418e-12\n"
     ]
    }
   ],
   "source": [
    "# APPROXIMATE SOLUTION\n",
    "term_frequency_table_frac_approx = term_frequency_table / (term_frequency_table.sum(axis=1) + 1e-12)[:, np.newaxis]\n",
    "print('Approximation error in l2 distance:', np.linalg.norm(term_frequency_table_frac_approx - term_frequency_table_frac))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c567f8b",
   "metadata": {},
   "source": [
    "Next, write code that creates a 1D numpy array called `world_history_mask`, where the number of entries is given by `len(subset_categories)`, and the i-th entry is 1 if `subset_categories[i]` is equal to `\"WORLD HISTORY\"`, and the i-th entry is 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66369e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "world_history_mask = 1*(np.array(subset_categories) == 'WORLD HISTORY')\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1ce89",
   "metadata": {},
   "source": [
    "**Solution remark:** If you did not have \"1*\" before the boolean mask array, you will also receive full credit, and in fact the PCA plotting code below will still work as desired. We multiply by 1 here just to have the answer actually match what we're asking you to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b9ee8",
   "metadata": {},
   "source": [
    "**Alternate solution 1:** Here's another example solution using a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4d4e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "world_history_mask = np.array([1*(category == 'WORLD HISTORY') for category in subset_categories])\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94704f82",
   "metadata": {},
   "source": [
    "**Alternate solution 2:** Here's yet another solution, this time more back-to-basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "387fca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------- YOUR CODE HERE ----------------------------->\n",
    "world_history_mask = []\n",
    "for category in subset_categories:\n",
    "    if category == 'WORLD HISTORY':\n",
    "        world_history_mask.append(1)\n",
    "    else:\n",
    "        world_history_mask.append(0)\n",
    "world_history_mask = np.array(world_history_mask)\n",
    "# <------------------- END OF YOUR CODE --------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5505e34",
   "metadata": {},
   "source": [
    "If your code is correct, then the code cell below should plot the 2D PCA representation for you and also print out the explained variance ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a607fb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratios: [0.03682397 0.02233863]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT MODIFY\n",
    "pca = PCA(n_components=2)\n",
    "feature_vectors_pca2d = pca.fit_transform(term_frequency_table_frac)\n",
    "scatter = plt.scatter(feature_vectors_pca2d[:, 0], feature_vectors_pca2d[:, 1],\n",
    "                      c=world_history_mask,\n",
    "                      cmap='Set3', alpha=0.7)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=['Literature', 'World History'])\n",
    "plt.axis('equal')\n",
    "\n",
    "print('Explained variance ratios:', pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd01b7",
   "metadata": {},
   "source": [
    "Even though the explained variance is low, it should be clear from the plot that questions from the two categories can actually often be distinguished from each other based on this 2D PCA representation!\n",
    "\n",
    "Which of the two principal components would you focus on to try to identify words most related to `\"WORLD HISTORY\"`? Would these words have the most negative or the most positive weights for this particular principal component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58efb8",
   "metadata": {},
   "source": [
    "**Your answer here (do not write code for this problem; please answer this as a non-coding question):** From the plot, we can see that the *negative* part of PC2 is where \"WORLD HISTORY\" Jeopardy questions mostly are. Because of how the feature vectors are defined, higher feature vector values correspond to more of specific words being present. Intuitively, for a specific Jeopardy question, if more words show up in it that are indicative of \"WORLD HISTORY\", then we would expect the PC2 value to be closer to where the yellow points are in the plot above--toward the negative direction of PC2. Thus, we should expect words indicative of \"WORLD HISTORY\" to tend to have *negative* PC2 weights.\n",
    "\n",
    "Note that while we explicitly asked you not to answer this question using code, just for this solution key, we also write some code for you to verify that our answer above is indeed true. In particular, we sort the PC2 weights from most negative to most positive (note that here we do *not* need to take the absolute value of the weights like we did in lecture, and we also sort in ascending order, smallest to largest since the smallest values will correspond to the most negative weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd899487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('country', -0.49290008934877383),\n",
       " ('government', -0.04919656911382324),\n",
       " ('king', -0.04897870510592394),\n",
       " ('set', -0.04667578390768739),\n",
       " ('constitution', -0.04073685705621684),\n",
       " ('established', -0.04064834096676351),\n",
       " ('ruled', -0.03351216563344515),\n",
       " ('1888', -0.03177965002988849),\n",
       " ('dynasty', -0.02375460907725619),\n",
       " ('called', -0.023254633516784334)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(zip(vocab, pca.components_[1]), key=lambda x: x[1]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52a382",
   "metadata": {},
   "source": [
    "The word with the most negative weight (\"country\") is the same as the most popular word for \"WORLD HISTORY\" found in **subpart iv**. We remark that \"country\" has a *very* large negative weight compared to all the other negative weights. Of course, we can't expect the words here to be identical to the ones we saw earlier in **subpart iv** as many of these words still do show up in \"LITERATURE\" as well."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "81de71fe"
   ],
   "name": "Quiz 1 Programming.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

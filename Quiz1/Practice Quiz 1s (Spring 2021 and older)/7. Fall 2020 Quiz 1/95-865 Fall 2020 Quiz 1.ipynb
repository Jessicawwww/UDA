{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt08zzFL_o0M"
   },
   "source": [
    "# 95-865 Fall 2020 Quiz 1\n",
    "\n",
    "You must fill in your name and your Andrew ID for this quiz to be graded. Moreover, filling out your name and Andrew ID below will serve as your agreement with us, the course staff, that you did not collaborate with anyone on this exam and that what you submit is truly your own individual work and not that of anyone else. Violations found will result in severe penalties.\n",
    "\n",
    "**Your name:** REPLACE THIS WITH YOUR NAME\n",
    "\n",
    "**Your Andrew ID:** REPLACE THIS WITH YOUR ANDREW ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Investigating Hospital Room Usage [40 points]\n",
    "\n",
    "**This problem is mostly conceptual. The last part has a short coding component.**\n",
    "\n",
    "Steel City Hospital is trying to understand how their patients use rooms in their main hospital building. They have grouped different kinds of appointments into three appointment types. Consider the following co-occurrence table that counts minutes spent in different hospital rooms by patients with different appointment types. Steel City Hospital collected this table using data for patients who made appointments within the most recent 3 months.\n",
    "\n",
    "\n",
    "| &nbsp; | Hospital Room 1 | Hospital Room 2 | Hospital Room 3 | Hospital Room 4 | Hospital Room 5 |\n",
    "| ------ | ------------- |-|-|-|-|\n",
    "| Appointment Type 1 | 0 | 320 | 0 | 0 | 80 |\n",
    "| Appointment Type 2 | 0 | 240 | 120 | 0 | 240 |\n",
    "| Appointment Type 3 | 90 | 0 | 0 | 1620 | 90 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) [5 points]** How many pairs of appointment type/hospital room have a PMI value of negative infinity?\n",
    "\n",
    "Number of pairs with negative infinity PMI value:\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER\n",
    "\n",
    "Briefly justify how you got your answer:\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) [15 points]** Let's focus on appointment type 2. Rank the PMIs of appointment type 2 with each of the hospital rooms from largest to smallest (only for rooms 2, 3, 4, and 5).\n",
    "\n",
    "Specifically, we are asking you to rank the PMI's of the pairs:\n",
    "\n",
    "- appointment type 2, hospital room 2\n",
    "- appointment type 2, hospital room 3\n",
    "- appointment type 2, hospital room 4\n",
    "- appointment type 2, hospital room 5\n",
    "\n",
    "For example, if you think the ranking of PMI's from largest to smallest is room 5, 4, 3, and 2, then you should write \"5, 4, 3, 2\".\n",
    "\n",
    "Write the ranking of PMI's in decreasing order here:\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER\n",
    "\n",
    "Briefly justify how you got the ranking you specified:\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "It turns out that we have some more information about how the hospital rooms are used. Specifically, each patient's appointment can involve multiple events (for example, a patient shows up and then has a first event corresponding to waiting, and then can have a second event corresponding to getting a medical exam or getting an X-ray). Here is a co-occurrence table for how many minutes are spent for different events in different rooms.\n",
    "\n",
    "| &nbsp; | Hospital Room 1 | Hospital Room 2 | Hospital Room 3 | Hospital Room 4 | Hospital Room 5 |\n",
    "| ------ | ------------- |-|-|-|-|\n",
    "| Event: Waiting | 0 | 0 | 0 | 0 | 410 |\n",
    "| Event: Exam | 0 | 560 | 0 | 0 | 0 |\n",
    "| Event: Blood draw | 90 | 0 | 0 | 0 | 0 |\n",
    "| Event: X-ray | 0 | 0 | 120 | 0 | 0 |\n",
    "| Event: Infusion | 0 | 0 | 0 | 1620 | 0 |\n",
    "\n",
    "For example, 90 minutes are spent by all patients getting blood drawn from room 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) [5 points]** What is Cramer's V for _event vs hospital room_?\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER\n",
    "\n",
    "Briefly justify how you got the Cramer's V value you specified:\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) [5 points]** Given the co-occurrence tables we have already provided (_appointment type vs room_, and separately _event vs room_), is it possible to construct the co-occurrence table for _appointment type vs event_ (there would be three rows for appointment types 1, 2, and 3, and five columns for the different events)?\n",
    "\n",
    "Say yes or no, and briefly justify your answer:\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We also have a co-occurrence table for events and the number of months in advance that an appointment was made, where once again each count in the table corresponds to minutes.\n",
    "\n",
    "\n",
    "| &nbsp; | 1 month in advance | 2 months in advance | 3 months in advance |\n",
    "| ------ | ------------- |-|-|\n",
    "| Event: Waiting | 137 | 138 | 135 |\n",
    "| Event: Exam | 185 | 189 | 186 |\n",
    "| Event: Blood draw | 33 | 30 | 27 |\n",
    "| Event: X-ray | 45 | 36 | 39 |\n",
    "| Event: Infusion | 530 | 543 | 547 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) [10 points]** Compute Cramer's V for _event vs months in advance an appointment was made_. Complete this in the code cell below. We have provided some starter code for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "co_table = np.array([[137, 138, 135],\n",
    "                     [185, 189, 186],\n",
    "                     [33, 30, 27],\n",
    "                     [45, 36, 39],\n",
    "                     [530, 543, 547]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the final Cramer's V value for _event vs months in advance an appointment was made_ ? (Copy and paste this numerical value from your executed code above)\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think _event vs months in advance an appointment was made_ is an interesting relationship to explore for the data? Very briefly explain why or why not.\n",
    "\n",
    "**Your answer:** REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. What Are People Singing About? [60 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2yue1u-_-By"
   },
   "source": [
    "**Before starting this problem, please be sure to download the dataset: http://www.andrew.cmu.edu/user/georgech/95-865/mystery_data_8EB52w.zip**\n",
    "\n",
    "In this problem, we're going to look at a music dataset to understand what artists are singing about across many songs. There are many ways one can go about doing this analysis. We will try something simple: we'll just focus on song titles, while keeping track of who the artists are for the different songs. We use a preprocessed version of the Billboard 1964-2015 Top 100 Lyrics dataset. Specifically, the following code cell loads in the following Python variables:\n",
    "\n",
    "- `song_titles`: a 1D numpy array of strings, each string corresponding to a song title\n",
    "- `song_artists`: a 1D numpy array of strings, each string corresponding to a song artist; the i-th artist corresponds to the i-th song in `song_titles`\n",
    "- `vocabulary`: a 1D numpy array of strings, each string corresponding to a vocabulary word\n",
    "- `song_title_feature_vectors`: a 2D array/table, where rows index different songs and columns index features; the i-th row corresponds to the i-th entry in `song_titles`, and the j-th column corresponds to the j-th entry in `vocabulary` -- note that the feature vectors are precisely the histograms of words in `vocabulary` for each song (raw counts of each word appearing; not fractional frequencies)\n",
    "\n",
    "Be sure to run this next cell before doing the rest of the problem. **Important:** The exam is written so that all the packages that need to be imported are already imported in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4g9XyJV-Uaf"
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL -- ** BE SURE TO RUN THIS CELL **\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "with open('mystery_titles.txt', 'r') as f:\n",
    "    song_titles = [line.strip() for line in f.readlines()]\n",
    "with open('mystery_artists.txt', 'r') as f:\n",
    "    song_artists = [line.strip() for line in f.readlines()]\n",
    "with open('mystery_features.txt', 'r') as f:\n",
    "    vocabulary = [line.strip() for line in f.readlines()]\n",
    "\n",
    "song_titles = np.asarray(song_titles)\n",
    "song_artists = np.asarray(song_artists)\n",
    "vocabulary = np.asarray(vocabulary)\n",
    "\n",
    "song_title_feature_vectors = np.loadtxt('mystery_feature_vectors.txt')\n",
    "\n",
    "print(song_titles.shape)\n",
    "print(song_artists.shape)\n",
    "print(vocabulary.shape)\n",
    "print(song_title_feature_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `song_titles.shape[0]` is equal to `song_artists.shape[0]` and also to `song_title_feature_vectors.shape[0]` (namely 2220 songs). Meanwhile, `vocabulary.shape[0]` is equal to `song_title_feature_vectors.shape[1]` (namely 65 words).\n",
    "\n",
    "To help you understand the variables a little bit, consider the 165th song title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_titles[165]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the code above, you should get the song title `'sweet sweet baby since youve been gone'`.\n",
    "\n",
    "To get the artist for the 165th song, you can use the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_artists[165]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The song artist in this case is `'aretha franklin'`.\n",
    "\n",
    "The song feature vector is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_title_feature_vectors[165]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the above cell, the output you get should be `array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])`.\n",
    "\n",
    "Note that nearly all the words in the vocabulary appear 0 times, but there are two words that appear once each, and one word that appears twice. We can easily figure out what these words are using code such as what is in the snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_idx in range(vocabulary.shape[0]):\n",
    "    if song_title_feature_vectors[165, word_idx] > 0:\n",
    "        print(word_idx, vocabulary[word_idx],\n",
    "              song_title_feature_vectors[165, word_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the above, the output you should get is:\n",
    "\n",
    "```\n",
    "3 baby 1.0\n",
    "19 gone 1.0\n",
    "53 sweet 2.0\n",
    "```\n",
    "\n",
    "This means that word index 3 corresponds to \"baby\", which appears once; word index 19 corresponds to \"gone\", which apppears once; lastly word index 53 corresponds to \"sweet\", which appears twice. Indeed, the title is \"sweet sweet baby since youve been gone\" (note that some of these words are excluded from the vocabulary and therefore ignored, namely \"since\", \"youve\", and \"been\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) [15 points total across subparts]** This is a warm-up problem, just to make sure you familiarize yourself with the data, and as a bit of basic Python coding review. **Extremely important: throughout this coding problem, you will not actually have to use `song_titles` and you can directly work with `song_title_feature_vectors` instead. We provide `song_titles` just in case you want to check it but you should not have to write any code that actually uses `song_titles`.**\n",
    "\n",
    "**Subpart i. [5 points]** How many songs have exactly one word in `vocabulary` show up exactly once (in other words, how many songs are there such that the song's feature vector has a sum of 1)? **Your Python code for this subpart should print out the answer to this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart ii. [5 points]** What word in `vocabulary` has the largest total raw count summed across songs? **Your Python code for this subpart should print out the answer to this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iii. [5 points]** How many songs have at least two distinct words in `vocabulary` show up? **Your Python code for this subpart should print out the answer to this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) [10 points]** One way to try to figure out what songs are about is to look at the \"term frequencies\" across all songs (the \"collection term frequencies\", as we saw in lecture). Plot a histogram of the top 10 most frequently occurring words (among those in `vocabulary`) according (raw counts summed across songs). The y-axis of your histogram should be the total raw count (summed across songs), and not a fractional frequency. Of course, the most frequently occurring word should be the same as what you got in part **(a)** subpart **ii**. **Your Python code for this subpart should plot a matplotlib histogram/bar chart.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "While collection term frequencies provide a summary of the whole dataset, they do not tell us about whether there are, for instance, songs that are similar. We explore this direction next.\n",
    "\n",
    "**(c) [15 points total across subparts]** To try to understand how the different songs relate, we first try PCA.\n",
    "\n",
    "**Subpart i. [5 points]** Compute the 2D PCA representation of `song_title_feature_vectors`, *without* doing any sort of normalization/standardization (i.e., directly fit a PCA model to `song_title_feature_vectors`). Plot this 2D PCA representation. What is the total fraction of variance explained? **Your Python code for this subpart should produce a scatter plot and also print out the total fraction of variance explained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart ii. [5 points]** Instead of what is done in subpart i, now first normalize `song_title_feature_vectors` using `StandardScaler` and then using the standardized representation of the feature vectors, compute and plot the resulting 2D PCA representation. What is the amount of variance explained? **Your Python code for this subpart should produce a scatter plot and also print out the total fraction of variance explained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iii. [5 points]** Of the two 2D PCA representations (the one from subpart **i** and the one from subpart **ii**), which one do you think is a better representation of the song feature vectors? Please briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer (do not write code for this subpart)**: REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) [20 points total across subparts]** Let's instead try t-SNE to represent the song feature vectors. To save you from the pain and agony of figuring out t-SNE parameters during the exam, we have precomputed the t-SNE representation for you, which you can load with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL -- ** BE SURE TO RUN THIS CELL **\n",
    "song_title_tsne_2d = np.loadtxt('mystery_vectors.txt')\n",
    "plt.scatter(song_title_tsne_2d[:, 0], song_title_tsne_2d[:, 1])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart i. [5 points]** From looking at the t-SNE 2D representation plot, do you think that this 2D data are well-modeled by a Gaussian mixture model? Briefly justify your answer.\n",
    "\n",
    "**Your answer (do not write code for this subpart)**: REPLACE THIS WITH YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart ii. [5 points]** Let's try to figure out if the little clumps mean anything. As a sanity check, let's look at the points with t-SNE x-coordinate less than -45 (these points form the leftmost clump of points in the plot above). We've highlighted these points for you in the code cell below (which points are in the leftmost clump has already been computed for you below in the variable `leftmost_clump_mask`, which is a 1D numpy array of booleans, where the i-th entry being `True` means that it is in the leftmost clump, and `False` means that it is not in the leftmost clump):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL -- ** BE SURE TO RUN THIS CELL **\n",
    "song_title_tsne_2d = np.loadtxt('mystery_vectors.txt')\n",
    "leftmost_clump_mask = (song_title_tsne_2d[:, 0] < -45)\n",
    "plt.scatter(song_title_tsne_2d[:, 0], song_title_tsne_2d[:, 1],\n",
    "            c=leftmost_clump_mask, cmap='Spectral')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that all the songs in the leftmost clump of points has a specific word in `vocabulary` show up. Which word is this? Be sure to briefly justify your answer with the help of some code. **Your Python code for this subpart should not only print out the word that answers the question but also makes it clear how you are finding this word.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subpart iii. [10 points]** Let's investigate the big clump of points in the middle of the plot in subpart **ii**. We've already computed a boolean mask of which points belong to this big clump (loaded into the variable `big_clump_mask` in the code cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL -- ** BE SURE TO RUN THIS CELL **\n",
    "big_clump_mask = np.loadtxt('mystery_mask.txt').astype(np.bool)\n",
    "song_title_tsne_2d = np.loadtxt('mystery_vectors.txt')\n",
    "plt.scatter(song_title_tsne_2d[:, 0], song_title_tsne_2d[:, 1],\n",
    "            c=big_clump_mask, cmap='Spectral')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the songs in the big clump all have \"love\" in the title. For this big clump, compute and display the 8 most common artists across songs that are in the big clump (for the display, it is fine to just print out who these artists are along with how many songs they have in the big clump; you do *not* need to plot a histogram/bar chart). **Your Python code for this subpart should print out 8 different pairings of artist/number of songs the artist has in the big clump -- do not worry about ties (so if two artists both have the same number of songs in the big clump, then you can list them in any order). Hint: You may find it helpful to use `Counter()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Fall_2020_quiz1_coding_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
